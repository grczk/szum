{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import and some path preparation",
   "id": "cd67bce93de11c8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:58:18.676877Z",
     "start_time": "2025-04-06T20:58:18.139627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import glob\n",
    "import os\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from random import Random\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import shutil\n",
    "from IPython.core.display import HTML\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ],
   "id": "9667dd77fc09dab9",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 12\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mIPython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdisplay\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HTML\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pyplot \u001B[38;5;28;01mas\u001B[39;00m plt\n\u001B[1;32m---> 12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimage\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ImageDataGenerator\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:58:21.857111Z",
     "start_time": "2025-04-06T20:58:21.853651Z"
    }
   },
   "cell_type": "code",
   "source": "main_szum_path = \"...\"",
   "id": "c8ac1f34e4d5a6d3",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:57:44.912527Z",
     "start_time": "2025-04-06T18:57:44.909383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datasets = {\n",
    "    \"Recognize Animals\": f\"{main_szum_path}/datasets/data1\",\n",
    "    \"Unsplash\": f\"{main_szum_path}/datasets/data4\",\n",
    "    \"Smoker Detection [Image] classification Dataset\": f\"{main_szum_path}/datasets/data3\",\n",
    "}"
   ],
   "id": "7aaae1124bb98f77",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Merging test/valid/train in datasets",
   "id": "e2fcb2a6a986a058"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Smoker Detection [Image] classification Dataset separation",
   "id": "9bdf3d17b02c8fcb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:57:45.289324Z",
     "start_time": "2025-04-06T18:57:44.918784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    os.mkdir(f\"{datasets[\"Smoker Detection [Image] classification Dataset\"]}/not_smoking\")\n",
    "except FileExistsError:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(f\"{datasets[\"Smoker Detection [Image] classification Dataset\"]}/smoking\")\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "lista = glob.glob(f\"{datasets[\"Smoker Detection [Image] classification Dataset\"]}/**/notsmoking*.*\",recursive=True)\n",
    "for file in lista:\n",
    "    Path(file).rename(f\"{datasets[\"Smoker Detection [Image] classification Dataset\"]}/not_smoking/{os.path.basename(file)}\")\n",
    "\n",
    "lista = glob.glob(f\"{datasets[\"Smoker Detection [Image] classification Dataset\"]}/**/smoking*.*\",recursive=True)\n",
    "for file in lista:\n",
    "    Path(file).rename(f\"{datasets[\"Smoker Detection [Image] classification Dataset\"]}/smoking/{os.path.basename(file)}\")"
   ],
   "id": "c95bd422bc5bd46e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Recognize Animals separation",
   "id": "d030471ecddc8dc2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:57:47.998396Z",
     "start_time": "2025-04-06T18:57:45.296352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    os.mkdir(f\"{datasets[\"Recognize Animals\"]}/none\")\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "lista = glob.glob(f\"{datasets[\"Recognize Animals\"]}/**/*.*\",recursive=True)\n",
    "for file in lista:\n",
    "    Path(file).rename(f\"{datasets[\"Recognize Animals\"]}/none/{os.path.basename(file)}\")"
   ],
   "id": "81941db15d4b4d84",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset statistics",
   "id": "d5cb8d51d638e85c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:57:51.800101Z",
     "start_time": "2025-04-06T18:57:48.005028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datasets_lists = []\n",
    "for key, value in datasets.items():\n",
    "    print(f\"Processing: {key}\")\n",
    "    smoking_list = glob.glob(f\"{value}/smoking/*.*\")\n",
    "    not_smoking_list = glob.glob(f\"{value}/not_smoking/*.*\")\n",
    "    none_list = glob.glob(f\"{value}/none/*.*\")\n",
    "    all_list = glob.glob(f\"{value}/**/*.*\",recursive=True)\n",
    "\n",
    "    image_list = []\n",
    "    for i in all_list:\n",
    "        try:\n",
    "            with Image.open(i) as img:\n",
    "                img.convert('RGB')\n",
    "                image_list.append(img)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    datasets_lists.append({\n",
    "        \"key\": key,\n",
    "        \"smoking_list\": smoking_list,\n",
    "        \"not_smoking_list\": not_smoking_list,\n",
    "        \"none_list\": none_list,\n",
    "        \"image_list\": image_list,\n",
    "        \"all_list\": all_list,\n",
    "    })"
   ],
   "id": "be9f7b752a88fba8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Recognize Animals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:57:51.801164900Z",
     "start_time": "2025-04-06T18:29:40.970291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for data in datasets_lists:\n",
    "    size_list = [i.size for i in data[\"image_list\"]]\n",
    "    type_count_list = Counter([i.format for i in data[\"image_list\"]])\n",
    "    display()\n",
    "    display(HTML(f\"\"\"\n",
    "        <h1>{data[\"key\"]}</h1>\n",
    "        <p><b>Smoking count:</b> {len(data[\"smoking_list\"])} ({len(data[\"smoking_list\"])/len(data[\"all_list\"]) * 100}%)</p>\n",
    "        <p><b>Not smoking count:</b> {len(data[\"not_smoking_list\"])} ({len(data[\"not_smoking_list\"])/len(data[\"all_list\"]) * 100}%)</p>\n",
    "        <p><b>none count:</b> {len(data[\"none_list\"])} ({len(data[\"none_list\"])/len(data[\"all_list\"]) * 100}%)</p>\n",
    "        <p><b>Max size:</b> {max(size_list)}; <b>Min size:</b> {min(size_list)}</p>\n",
    "        <p><b>Type count:</b></p> <ul>{\"\".join([f\"<li>{k}: {v}</li>\" for k,v in type_count_list.items()])}</ul>\n",
    "    \"\"\"))"
   ],
   "id": "5d8cc6418086722",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "        <h1>Recognize Animals</h1>\n",
       "        <p><b>Smoking count:</b> 0 (0.0%)</p>\n",
       "        <p><b>Not smoking count:</b> 0 (0.0%)</p>\n",
       "        <p><b>Other count:</b> 9108 (100.0%)</p>\n",
       "        <p><b>Max size:</b> (640, 640); <b>Min size:</b> (65, 64)</p>\n",
       "        <p><b>Type count:</b></p> <ul><li>JPEG: 9058</li><li>PNG: 48</li></ul>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "        <h1>Unsplash</h1>\n",
       "        <p><b>Smoking count:</b> 500 (50.0%)</p>\n",
       "        <p><b>Not smoking count:</b> 500 (50.0%)</p>\n",
       "        <p><b>Other count:</b> 0 (0.0%)</p>\n",
       "        <p><b>Max size:</b> (250, 250); <b>Min size:</b> (250, 250)</p>\n",
       "        <p><b>Type count:</b></p> <ul><li>JPEG: 1000</li></ul>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "        <h1>Smoker Detection [Image] classification Dataset</h1>\n",
       "        <p><b>Smoking count:</b> 560 (50.0%)</p>\n",
       "        <p><b>Not smoking count:</b> 560 (50.0%)</p>\n",
       "        <p><b>Other count:</b> 0 (0.0%)</p>\n",
       "        <p><b>Max size:</b> (250, 250); <b>Min size:</b> (250, 250)</p>\n",
       "        <p><b>Type count:</b></p> <ul><li>JPEG: 1120</li></ul>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Merging all datasets to one",
   "id": "19716541812a4e20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:58:44.222559Z",
     "start_time": "2025-04-06T20:58:44.218918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "paths = [\n",
    "    f\"{main_szum_path}/not_smoking\",\n",
    "    f\"{main_szum_path}/smoking\",\n",
    "    f\"{main_szum_path}/none\"\n",
    "]"
   ],
   "id": "818fa5d530d49bd1",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:57:51.811510600Z",
     "start_time": "2025-04-06T18:30:15.789215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for data in datasets_lists:\n",
    "    for i in paths:\n",
    "        try:\n",
    "            os.mkdir(i)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        for file in data[f\"{os.path.basename(i)}_list\"]:\n",
    "            shutil.copy(file, f\"{i}/{os.path.basename(file)}\")"
   ],
   "id": "1c2ef250f59020b8",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:57:51.812507700Z",
     "start_time": "2025-04-06T18:30:52.608813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lista = [(os.path.basename(path),len(glob.glob(f\"{path}/*.*\"))) for path in paths]\n",
    "all_count = sum([v for _,v in lista])\n",
    "display(HTML(f\"\"\"\n",
    "    <h1>Merged datasets</h1>\n",
    "    <ul>{\"\".join([f\"<li><b>{k}:</b> {v} ({v/all_count *100}%)</li>\" for k, v in lista])}</ul>\n",
    "\"\"\"))"
   ],
   "id": "7cf3655208979b59",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <h1>Merged datasets</h1>\n",
       "    <ul><li><b>not_smoking:</b> 1060 (9.440684004275028%)</li><li><b>smoking:</b> 1060 (9.440684004275028%)</li><li><b>other:</b> 9108 (81.11863199144994%)</li></ul>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Filter images based on their size",
   "id": "8bee2f3593b78ae2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:57:51.825016200Z",
     "start_time": "2025-04-06T18:32:57.205710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for path in paths:\n",
    "    small_photo = []\n",
    "    for filename in os.listdir(path):\n",
    "        filepath = os.path.join(path, filename)\n",
    "        if os.path.isfile(filepath):\n",
    "            try:\n",
    "                with Image.open(filepath) as img:\n",
    "                    width, height = img.size\n",
    "                    if width < 200 or height < 200:\n",
    "                        small_photo.append(filepath)\n",
    "            except Exception as e:\n",
    "                print(f\"Error in open {filename}: {e}\")\n",
    "\n",
    "    try:\n",
    "        os.mkdir(f\"{path}\\\\small_photo\")\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    for file in small_photo:\n",
    "        Path(file).rename(f\"{path}/small_photo/{os.path.basename(file)}\")"
   ],
   "id": "f8ac48d0efa283dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in open filenames.txt: cannot identify image file 'C:/Users/kubix23/OneDrive/Pulpit/Szum/other\\\\filenames.txt'\n",
      "Error in open filenames_elefante_train.txt: cannot identify image file 'C:/Users/kubix23/OneDrive/Pulpit/Szum/other\\\\filenames_elefante_train.txt'\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:57:51.832575100Z",
     "start_time": "2025-04-06T18:34:13.828792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lista = [(os.path.basename(path),len(glob.glob(f\"{path}/*.*\"))) for path in paths]\n",
    "all_count = sum([v for _,v in lista])\n",
    "display(HTML(f\"\"\"\n",
    "    <h1>Merged datasets after size filter</h1>\n",
    "    <ul>{\"\".join([f\"<li><b>{k}:</b> {v} ({v/all_count *100}%)</li>\" for k, v in lista])}</ul>\n",
    "\"\"\"))"
   ],
   "id": "40a0999545c9ab69",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <h1>Merged datasets after size filter</h1>\n",
       "    <ul><li><b>not_smoking:</b> 1060 (11.447084233261338%)</li><li><b>smoking:</b> 1060 (11.447084233261338%)</li><li><b>other:</b> 7140 (77.10583153347731%)</li></ul>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Filter images based on their format/type",
   "id": "8bf8c4e937aa41a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T18:57:51.834555200Z",
     "start_time": "2025-04-06T18:34:27.814202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for path in paths:\n",
    "    try:\n",
    "        os.mkdir(f\"{path}/not_jpg\")\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    for filename in [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]:\n",
    "        if Path(filename).suffix.lower() not in ['.jpg', '.jpeg']:\n",
    "            Path(f\"{path}/{filename}\").rename(f\"{path}/not_jpg/{filename}\")"
   ],
   "id": "94c2030c1b185671",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lista = [(os.path.basename(path),len(glob.glob(f\"{path}/*.*\"))) for path in paths]\n",
    "all_count = sum([v for _,v in lista])\n",
    "display(HTML(f\"\"\"\n",
    "    <h1>Merged datasets after format filter</h1>\n",
    "    <ul>{\"\".join([f\"<li><b>{k}:</b> {v} ({v/all_count *100}%)</li>\" for k, v in lista])}</ul>\n",
    "\"\"\"))"
   ],
   "id": "9376c589a71defe7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T21:25:47.957444Z",
     "start_time": "2025-04-06T21:25:46.393235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_all_images():\n",
    "    result = []\n",
    "    for i, path in enumerate(paths):\n",
    "        for j in glob.glob(f\"{path}/*.*\"):\n",
    "            try:\n",
    "                with Image.open(j) as img:\n",
    "                    result.append((np.array(img), i))\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    return result\n",
    "image_list = get_all_images()"
   ],
   "id": "2264ff5161e6c70d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def standardization(dataset):\n",
    "    mean = np.mean((np.concatenate([arr.flatten() for arr in [i for i,j in image_list]])))\n",
    "    std = np.std((np.concatenate([arr.flatten() for arr in [i for i,j in image_list]])))\n",
    "    return [((image - mean) / std,label) for image, label in image_list]\n",
    "\n",
    "def normalization(dataset):\n",
    "    return [(image / 255.0, label) for image, label in image_list]"
   ],
   "id": "f036052f05bc9ea0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T21:00:10.496411Z",
     "start_time": "2025-04-06T21:00:07.165624Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 9,
   "source": [
    "def create_split(dataset):\n",
    "    train_set = dataset[:int(len(dataset)*0.8)]\n",
    "    val_set = dataset[int(len(dataset)*0.8):int(len(dataset)*0.9)]\n",
    "    test_set = dataset[int(len(dataset)*0.9):int(len(dataset)-1)]\n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "create_split(image_list)"
   ],
   "id": "99fa5529e144da94"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    shear_range=0.2,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "for path in paths:\n",
    "    generator = datagen.flow_from_directory(path, batch_size=1)\n",
    "    for i in range(len(generator.filenames) * 5):  # 5 augmentacji na plik\n",
    "        generator.next()"
   ],
   "id": "cfefc339830c433c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "image_list = get_all_images()\n",
    "\n",
    "def create_split_2(dataset):\n",
    "    temp = {}\n",
    "    for array, label in dataset:\n",
    "        temp[label].append((array, label))\n",
    "    dataset = []\n",
    "    for label,values in temp.values():\n",
    "        dataset.extend(values[:1060])\n",
    "    standardization_image_list = standardization(image_list)\n",
    "    return create_split(standardization_image_list)"
   ],
   "id": "2a7acacd3b26e428",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_split_3(dataset):\n",
    "    temp = {}\n",
    "    for array, label in dataset:\n",
    "        temp[label].append((array, label))\n",
    "    dataset = []\n",
    "    for label,values in temp.values():\n",
    "        dataset.extend(values[:1060])\n",
    "    standardization_image_list = standardization(image_list)\n",
    "    train_set = dataset[:int(len(standardization_image_list)*0.9)]\n",
    "    val_set = dataset[int(len(standardization_image_list)*0.8):int(len(standardization_image_list)*0.9)]\n",
    "    test_set = dataset[int(len(standardization_image_list)*0.9):int(len(standardization_image_list)-1)]\n",
    "    return train_set, val_set, test_set"
   ],
   "id": "eb77e662fad9c34a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
